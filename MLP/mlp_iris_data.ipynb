{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dependency libraries\n",
    "from random import seed\n",
    "from random import randrange\n",
    "from random import random\n",
    "from csv import reader\n",
    "from math import exp\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "utA4R-KcOU6l",
    "outputId": "32403c04-44df-4619-a0c3-56660b419e82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the Dataset\n",
    "iris = load_iris()\n",
    "type(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UONtVe-z6qaA",
    "outputId": "96be8934-8738-47f4-f938-a1cb9f53fd9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "# Names of features/columns in iris dataset\n",
    "print(iris.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7R8tyVlv6uM8",
    "outputId": "bd922c5c-97e4-471b-f8f6-7e51fdd66661"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shape of dataset\n",
    "iris.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "vG60gU6OONSN"
   },
   "outputs": [],
   "source": [
    "#Function to formatting dataset\n",
    "def data_set(data,target):\n",
    "  data = data.tolist()\n",
    "  for i in range(len(data)):\n",
    "    data[i].extend([target[i]])\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "kYRIBXloOaYG"
   },
   "outputs": [],
   "source": [
    "data = iris.data\n",
    "target = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kIEDbaQxOddn",
    "outputId": "8fed3a84-2bf8-476d-c89a-8fa8f72bcbc2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#formatting dataset\n",
    "iris_dataset = data_set(data,target)\n",
    "len(iris_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split a dataset into k folds\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "        dataset_split = list()\n",
    "        dataset_copy = list(dataset)\n",
    "        fold_size = int(len(dataset) / n_folds)\n",
    "        for i in range(n_folds):\n",
    "                fold = list()\n",
    "                while len(fold) < fold_size:\n",
    "                        index = randrange(len(dataset_copy))\n",
    "                        fold.append(dataset_copy.pop(index))\n",
    "                dataset_split.append(fold)\n",
    "        return dataset_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a vanilla neural network based on required neurons in layer\n",
    "def initialize_network(n_inputs, n_hidden, n_outputs):\n",
    "        network = list()\n",
    "        hidden_layer = [{'weights':[random() for i in range(n_inputs + 1)], 'prev':[0 for i in range(n_inputs+1)]} for i in range(n_hidden)]        \n",
    "        network.append(hidden_layer)\n",
    "        output_layer = [{'weights':[random() for i in range(n_hidden + 1)],'prev':[0 for i in range(n_hidden+1)]} for i in range(n_outputs)]\n",
    "        network.append(output_layer)\n",
    "        #print(network)\n",
    "        return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method to calculate net value for each neuron in a layer\n",
    "def activate(weights, inputs):\n",
    "        #Get the bias value \n",
    "        activation = weights[-1]\n",
    "        #calculate neuron net value\n",
    "        for i in range(len(weights)-1):\n",
    "                activation += weights[i] * inputs[i]\n",
    "        return activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer neuron activation(using sigmoid activation function)\n",
    "def transfer(activation):\n",
    "        return 1.0 / (1.0 + exp(-activation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward propagate input to a network output\n",
    "def forward_propagate(network, row):\n",
    "        inputs = row\n",
    "        #loop through each layer in network\n",
    "        for layer in network:\n",
    "                new_inputs = []\n",
    "                #loop through each neuron in layer\n",
    "                for neuron in layer:\n",
    "                        #calculate linear transformation for a neuron by taking input(each row)\n",
    "                        activation = activate(neuron['weights'], inputs)\n",
    "                        \n",
    "                        #passing linear transformation output to Activationfunction\n",
    "                        neuron['output'] = transfer(activation)\n",
    "                        \n",
    "                        #add the each neuron output into new_inputs to pass it to next layer of neurons\n",
    "                        new_inputs.append(neuron['output'])\n",
    "                inputs = new_inputs\n",
    "                \n",
    "        #return the output for each row in dataset        \n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a network for a fixed number of epochs\n",
    "def train_network(network, train, l_rate, n_epoch, n_outputs):\n",
    "        epochs=[]\n",
    "        accuracy=[]\n",
    "        for epoch in range(n_epoch):\n",
    "                results=[]\n",
    "                for row in train:\n",
    "                        outputs = forward_propagate(network, row)\n",
    "                        #Converting probability values into 0 or 1\n",
    "                        pred = [int(i > .5) for i in outputs]\n",
    "                        \n",
    "                        #get the expected results                        \n",
    "                        expected = [0 for i in range(n_outputs)]\n",
    "                        expected[row[-1]] = 1\n",
    "                        \n",
    "                        row_res = row_acc(expected,pred)\n",
    "                        results.extend(row_res)\n",
    "                            \n",
    "                        #print(\"expected row{}\\n\".format(expected))\n",
    "                        backward_propagate_error(network, expected)\n",
    "                        update_weights(network, row, l_rate)\n",
    "                \n",
    "                accra=sum(results)/len(results)\n",
    "                accuracy.append(accra)\n",
    "                epochs.append(epoch)\n",
    "        return accuracy,epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation for each row output\n",
    "def row_acc(expected,pred):\n",
    "    accu=[]\n",
    "    if pred==expected:\n",
    "        accu.append(1)\n",
    "    else : accu.append(0)\n",
    "    return accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backpropagation Algorithm With Stochastic Gradient Descent\n",
    "def back_propagation(train, test, l_rate, n_epoch, n_hidden):\n",
    "        n_inputs = len(train[0]) - 1\n",
    "        n_outputs = len(set([row[-1] for row in train]))\n",
    "        network = initialize_network(n_inputs, n_hidden, n_outputs)\n",
    "        accuracy,epoch = train_network(network, train, l_rate, n_epoch, n_outputs)\n",
    "        #print(\"network {}\\n\".format(network))\n",
    "        predictions = list()\n",
    "        for row in test:\n",
    "                prediction = predict(network, row)\n",
    "                predictions.append(prediction)\n",
    "        return(predictions,accuracy,epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backpropagate error and store in neurons\n",
    "def backward_propagate_error(network, expected):\n",
    "        for i in reversed(range(len(network))):\n",
    "                layer = network[i]\n",
    "                errors = list()\n",
    "                if i != len(network)-1:\n",
    "                        for j in range(len(layer)):\n",
    "                                error = 0.0\n",
    "                                for neuron in network[i + 1]:\n",
    "                                        error += (neuron['weights'][j] * neuron['delta'])\n",
    "                                errors.append(error)\n",
    "                else:\n",
    "                        for j in range(len(layer)):\n",
    "                                neuron = layer[j]\n",
    "                                errors.append(expected[j] - neuron['output'])\n",
    "                for j in range(len(layer)):\n",
    "                        neuron = layer[j]\n",
    "                        neuron['delta'] = errors[j] * transfer_derivative(neuron['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the derivative of an neuron output\n",
    "def transfer_derivative(output):\n",
    "        return output * (1.0 - output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction with a network\n",
    "def predict(network, row):\n",
    "        outputs = forward_propagate(network, row)\n",
    "        return outputs.index(max(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update network weights with error\n",
    "def update_weights(network, row, l_rate):\n",
    "        for i in range(len(network)):\n",
    "                inputs = row[:-1]                \n",
    "                if i != 0:\n",
    "                        inputs = [neuron['output'] for neuron in network[i - 1]]\n",
    "                for neuron in network[i]:\n",
    "                        for j in range(len(inputs)):\n",
    "                                temp = l_rate * neuron['delta'] * inputs[j] + mu * neuron['prev'][j]\n",
    "                                \n",
    "                                neuron['weights'][j] += temp\n",
    "                                #print(\"neuron weight{} \\n\".format(neuron['weights'][j]))\n",
    "                                neuron['prev'][j] = temp\n",
    "                        temp = l_rate * neuron['delta'] + mu * neuron['prev'][-1]\n",
    "                        neuron['weights'][-1] += temp\n",
    "                        neuron['prev'][-1] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate an algorithm using a cross validation split\n",
    "def run_algorithm(dataset, algorithm, n_folds, *args):\n",
    "        \n",
    "        folds = cross_validation_split(dataset, n_folds)\n",
    "        #for fold in folds:\n",
    "                #print(\"Fold {} \\n \\n\".format(fold))\n",
    "        scores = list()\n",
    "        Nfold = 1\n",
    "        for fold in folds:\n",
    "                #print(\"Test Fold {} \\n \\n\".format(fold))\n",
    "                train_set = list(folds)\n",
    "                train_set.remove(fold)\n",
    "                train_set = sum(train_set, [])\n",
    "                test_set = list()\n",
    "                for row in fold:\n",
    "                        row_copy = list(row)\n",
    "                        test_set.append(row_copy)\n",
    "                        row_copy[-1] = None\n",
    "                predicted,accuarcy,epoch = algorithm(train_set, test_set, *args)\n",
    "          \n",
    "                #Get the actual target values from test dataset\n",
    "                actual = [row[-1] for row in fold]\n",
    "                #Evaluation for test dataset\n",
    "                accuracy = accuracy_met(actual, predicted)\n",
    "                cm = confusion_matrix(actual, predicted)\n",
    "                print('For Fold {} results:'.format(Nfold))\n",
    "                print('Confusion Matrix:')\n",
    "                print('\\n'.join([''.join(['{:4}'.format(item) for item in row]) for row in cm]))\n",
    "                confusionmatrix = np.matrix(cm)\n",
    "                FP = cm.sum(axis=0) - np.diag(cm)\n",
    "                FN = cm.sum(axis=1) - np.diag(cm)\n",
    "                TP = np.diag(cm)\n",
    "                TN = cm.sum() - (FP + FN + TP)\n",
    "                #print('False Positives\\n {}'.format(FP))\n",
    "                #print('False Negetives\\n {}'.format(FN))\n",
    "                #print('True Positives\\n {}'.format(TP))\n",
    "                #print('True Negetives\\n {}'.format(TN))\n",
    "                TPR = TP/(TP+FN)\n",
    "                print('Sensitivity \\n {}'.format(TPR))\n",
    "                TNR = TN/(TN+FP)\n",
    "                print('Specificity \\n {}'.format(TNR))\n",
    "                Precision = TP/(TP+FP)\n",
    "                print('Precision \\n {}'.format(Precision))\n",
    "                Recall = TP/(TP+FN)\n",
    "                print('Recall \\n {}'.format(Recall))\n",
    "                Acc = (TP+TN)/(TP+TN+FP+FN)\n",
    "                #print('√Åccuracy \\n{}'.format(Acc))\n",
    "                Fscore = 2*(Precision*Recall)/(Precision+Recall)\n",
    "                print('FScore \\n{}'.format(Fscore))\n",
    "                scores.append(accuracy)\n",
    "                Nfold+=1\n",
    "                print('\\n\\n')\n",
    "        #plt.plot(epoch, accuarcy, label = \"line 1\")\n",
    "        #print(epoch)\n",
    "        #print(accuarcy)\n",
    "        return (scores,epoch,accuarcy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy percentage\n",
    "def accuracy_met(actual, predicted):\n",
    "        correct = 0\n",
    "        for i in range(len(actual)):\n",
    "                if actual[i] == predicted[i]:\n",
    "                        correct += 1\n",
    "        return correct / float(len(actual)) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Backprop on Seeds dataset\n",
    "seed(1)\n",
    "\n",
    "# evaluate algorithm\n",
    "n_folds = 5\n",
    "l_rate = 0.1\n",
    "mu=0.001\n",
    "n_epoch = 100\n",
    "n_hidden = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Fold 1 results:\n",
      "Confusion Matrix:\n",
      "  11   0   0\n",
      "   1   6   1\n",
      "   0   0  11\n",
      "Sensitivity \n",
      " [1.   0.75 1.  ]\n",
      "Specificity \n",
      " [0.94736842 1.         0.94736842]\n",
      "Precision \n",
      " [0.91666667 1.         0.91666667]\n",
      "Recall \n",
      " [1.   0.75 1.  ]\n",
      "FScore \n",
      "[0.95652174 0.85714286 0.95652174]\n",
      "\n",
      "\n",
      "\n",
      "For Fold 2 results:\n",
      "Confusion Matrix:\n",
      "  10   0   0\n",
      "   0   9   2\n",
      "   0   0   9\n",
      "Sensitivity \n",
      " [1.         0.81818182 1.        ]\n",
      "Specificity \n",
      " [1.        1.        0.9047619]\n",
      "Precision \n",
      " [1.         1.         0.81818182]\n",
      "Recall \n",
      " [1.         0.81818182 1.        ]\n",
      "FScore \n",
      "[1.  0.9 0.9]\n",
      "\n",
      "\n",
      "\n",
      "For Fold 3 results:\n",
      "Confusion Matrix:\n",
      "   6   0   0\n",
      "   0  10   0\n",
      "   0  14   0\n",
      "Sensitivity \n",
      " [1. 1. 0.]\n",
      "Specificity \n",
      " [1.  0.3 1. ]\n",
      "Precision \n",
      " [1.         0.41666667        nan]\n",
      "Recall \n",
      " [1. 1. 0.]\n",
      "FScore \n",
      "[1.         0.58823529        nan]\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-57bffad2e5ea>:42: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Precision = TP/(TP+FP)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Fold 4 results:\n",
      "Confusion Matrix:\n",
      "  10   0   0\n",
      "   0   9   1\n",
      "   0   0  10\n",
      "Sensitivity \n",
      " [1.  0.9 1. ]\n",
      "Specificity \n",
      " [1.   1.   0.95]\n",
      "Precision \n",
      " [1.         1.         0.90909091]\n",
      "Recall \n",
      " [1.  0.9 1. ]\n",
      "FScore \n",
      "[1.         0.94736842 0.95238095]\n",
      "\n",
      "\n",
      "\n",
      "For Fold 5 results:\n",
      "Confusion Matrix:\n",
      "  13   0   0\n",
      "   0   6   5\n",
      "   0   0   6\n",
      "Sensitivity \n",
      " [1.         0.54545455 1.        ]\n",
      "Specificity \n",
      " [1.         1.         0.79166667]\n",
      "Precision \n",
      " [1.         1.         0.54545455]\n",
      "Recall \n",
      " [1.         0.54545455 1.        ]\n",
      "FScore \n",
      "[1.         0.70588235 0.70588235]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores,epoch,accuarcy = run_algorithm(iris_dataset, back_propagation, n_folds, l_rate, n_epoch, n_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'train_accuarcy')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot for epochs vs train accuracy\n",
    "plt.plot(epoch, accuarcy)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('train_accuarcy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[93.33333333333333,\n",
       " 93.33333333333333,\n",
       " 53.333333333333336,\n",
       " 96.66666666666667,\n",
       " 83.33333333333334]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy score for different test folds\n",
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
