{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dependency libraries\n",
    "from random import seed\n",
    "from random import randrange\n",
    "from random import random\n",
    "from csv import reader\n",
    "from math import exp\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "utA4R-KcOU6l",
    "outputId": "32403c04-44df-4619-a0c3-56660b419e82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the Dataset\n",
    "iris = load_iris()\n",
    "type(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UONtVe-z6qaA",
    "outputId": "96be8934-8738-47f4-f938-a1cb9f53fd9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "# Names of features/columns in iris dataset\n",
    "print(iris.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7R8tyVlv6uM8",
    "outputId": "bd922c5c-97e4-471b-f8f6-7e51fdd66661"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shape of dataset\n",
    "iris.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "vG60gU6OONSN"
   },
   "outputs": [],
   "source": [
    "#Function to formatting dataset\n",
    "def data_set(data,target):\n",
    "  data = data.tolist()\n",
    "  for i in range(len(data)):\n",
    "    data[i].extend([target[i]])\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "kYRIBXloOaYG"
   },
   "outputs": [],
   "source": [
    "data = iris.data\n",
    "target = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kIEDbaQxOddn",
    "outputId": "8fed3a84-2bf8-476d-c89a-8fa8f72bcbc2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#formatting dataset\n",
    "iris_dataset = data_set(data,target)\n",
    "len(iris_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split a dataset into k folds\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "        dataset_split = list()\n",
    "        dataset_copy = list(dataset)\n",
    "        fold_size = int(len(dataset) / n_folds)\n",
    "        for i in range(n_folds):\n",
    "                fold = list()\n",
    "                while len(fold) < fold_size:\n",
    "                        index = randrange(len(dataset_copy))\n",
    "                        fold.append(dataset_copy.pop(index))\n",
    "                dataset_split.append(fold)\n",
    "        return dataset_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a vanilla neural network based on required neurons in layer\n",
    "def initialize_network(n_inputs, n_hidden, n_outputs):\n",
    "        network = list()\n",
    "        hidden_layer = [{'weights':[random() for i in range(n_inputs + 1)], 'prev':[0 for i in range(n_inputs+1)]} for i in range(n_hidden)]        \n",
    "        network.append(hidden_layer)\n",
    "        output_layer = [{'weights':[random() for i in range(n_hidden + 1)],'prev':[0 for i in range(n_hidden+1)]} for i in range(n_outputs)]\n",
    "        network.append(output_layer)\n",
    "        #print(network)\n",
    "        return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method to calculate net value for each neuron in a layer\n",
    "def activate(weights, inputs):\n",
    "        #Get the bias value \n",
    "        activation = weights[-1]\n",
    "        #calculate neuron net value\n",
    "        for i in range(len(weights)-1):\n",
    "                activation += weights[i] * inputs[i]\n",
    "        return activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer neuron activation(using sigmoid activation function)\n",
    "def transfer(activation):\n",
    "        return 1.0 / (1.0 + exp(-activation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward propagate input to a network output\n",
    "def forward_propagate(network, row):\n",
    "        inputs = row\n",
    "        #loop through each layer in network\n",
    "        for layer in network:\n",
    "                new_inputs = []\n",
    "                #loop through each neuron in layer\n",
    "                for neuron in layer:\n",
    "                        #calculate linear transformation for a neuron by taking input(each row)\n",
    "                        activation = activate(neuron['weights'], inputs)\n",
    "                        \n",
    "                        #passing linear transformation output to Activationfunction\n",
    "                        neuron['output'] = transfer(activation)\n",
    "                        \n",
    "                        #add the each neuron output into new_inputs to pass it to next layer of neurons\n",
    "                        new_inputs.append(neuron['output'])\n",
    "                inputs = new_inputs\n",
    "                \n",
    "        #return the output for each row in dataset        \n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a network for a fixed number of epochs\n",
    "def train_network(network, train, l_rate, n_epoch, n_outputs):\n",
    "        epochs=[]\n",
    "        accuracy=[]\n",
    "        for epoch in range(n_epoch):\n",
    "                results=[]\n",
    "                for row in train:\n",
    "                        outputs = forward_propagate(network, row)\n",
    "                        #Converting probability values into 0 or 1\n",
    "                        pred = [int(i > .5) for i in outputs]\n",
    "                        \n",
    "                        #get the expected results                        \n",
    "                        expected = [0 for i in range(n_outputs)]\n",
    "                        expected[row[-1]] = 1\n",
    "                        \n",
    "                        row_res = row_acc(expected,pred)\n",
    "                        results.extend(row_res)\n",
    "                            \n",
    "                        #print(\"expected row{}\\n\".format(expected))\n",
    "                        backward_propagate_error(network, expected)\n",
    "                        update_weights(network, row, l_rate)\n",
    "                \n",
    "                accra=sum(results)/len(results)\n",
    "                accuracy.append(accra)\n",
    "                epochs.append(epoch)\n",
    "        return accuracy,epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation for each row output\n",
    "def row_acc(expected,pred):\n",
    "    accu=[]\n",
    "    if pred==expected:\n",
    "        accu.append(1)\n",
    "    else : accu.append(0)\n",
    "    return accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backpropagation Algorithm With Stochastic Gradient Descent\n",
    "def back_propagation(train, test, l_rate, n_epoch, n_hidden):\n",
    "        n_inputs = len(train[0]) - 1\n",
    "        n_outputs = len(set([row[-1] for row in train]))\n",
    "        network = initialize_network(n_inputs, n_hidden, n_outputs)\n",
    "        accuracy,epoch = train_network(network, train, l_rate, n_epoch, n_outputs)\n",
    "        #print(\"network {}\\n\".format(network))\n",
    "        predictions = list()\n",
    "        for row in test:\n",
    "                prediction = predict(network, row)\n",
    "                predictions.append(prediction)\n",
    "        return(predictions,accuracy,epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backpropagate error and store in neurons\n",
    "def backward_propagate_error(network, expected):\n",
    "        for i in reversed(range(len(network))):\n",
    "                layer = network[i]\n",
    "                errors = list()\n",
    "                if i != len(network)-1:\n",
    "                        for j in range(len(layer)):\n",
    "                                error = 0.0\n",
    "                                for neuron in network[i + 1]:\n",
    "                                        error += (neuron['weights'][j] * neuron['delta'])\n",
    "                                errors.append(error)\n",
    "                else:\n",
    "                        for j in range(len(layer)):\n",
    "                                neuron = layer[j]\n",
    "                                errors.append(expected[j] - neuron['output'])\n",
    "                for j in range(len(layer)):\n",
    "                        neuron = layer[j]\n",
    "                        neuron['delta'] = errors[j] * transfer_derivative(neuron['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the derivative of an neuron output\n",
    "def transfer_derivative(output):\n",
    "        return output * (1.0 - output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction with a network\n",
    "def predict(network, row):\n",
    "        outputs = forward_propagate(network, row)\n",
    "        return outputs.index(max(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update network weights with error\n",
    "def update_weights(network, row, l_rate):\n",
    "        for i in range(len(network)):\n",
    "                inputs = row[:-1]                \n",
    "                if i != 0:\n",
    "                        inputs = [neuron['output'] for neuron in network[i - 1]]\n",
    "                for neuron in network[i]:\n",
    "                        for j in range(len(inputs)):\n",
    "                                temp = l_rate * neuron['delta'] * inputs[j] + mu * neuron['prev'][j]\n",
    "                                \n",
    "                                neuron['weights'][j] += temp\n",
    "                                #print(\"neuron weight{} \\n\".format(neuron['weights'][j]))\n",
    "                                neuron['prev'][j] = temp\n",
    "                        temp = l_rate * neuron['delta'] + mu * neuron['prev'][-1]\n",
    "                        neuron['weights'][-1] += temp\n",
    "                        neuron['prev'][-1] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate an algorithm using a cross validation split\n",
    "def run_algorithm(dataset, algorithm, n_folds, *args):\n",
    "        \n",
    "        folds = cross_validation_split(dataset, n_folds)\n",
    "        #for fold in folds:\n",
    "                #print(\"Fold {} \\n \\n\".format(fold))\n",
    "        scores = list()\n",
    "        Nfold = 1\n",
    "        for fold in folds:\n",
    "                #print(\"Test Fold {} \\n \\n\".format(fold))\n",
    "                train_set = list(folds)\n",
    "                train_set.remove(fold)\n",
    "                train_set = sum(train_set, [])\n",
    "                test_set = list()\n",
    "                for row in fold:\n",
    "                        row_copy = list(row)\n",
    "                        test_set.append(row_copy)\n",
    "                        row_copy[-1] = None\n",
    "                predicted,accuarcy,epoch = algorithm(train_set, test_set, *args)\n",
    "          \n",
    "                #Get the actual target values from test dataset\n",
    "                actual = [row[-1] for row in fold]\n",
    "                #Evaluation for test dataset\n",
    "                accuracy = accuracy_met(actual, predicted)\n",
    "                cm = confusion_matrix(actual, predicted)\n",
    "                print('For Fold {} results:'.format(Nfold))\n",
    "                print('Confusion Matrix:')\n",
    "                print('\\n'.join([''.join(['{:4}'.format(item) for item in row]) for row in cm]))\n",
    "                confusionmatrix = np.matrix(cm)\n",
    "                FP = cm.sum(axis=0) - np.diag(cm)\n",
    "                FN = cm.sum(axis=1) - np.diag(cm)\n",
    "                TP = np.diag(cm)\n",
    "                TN = cm.sum() - (FP + FN + TP)\n",
    "                #print('False Positives\\n {}'.format(FP))\n",
    "                #print('False Negetives\\n {}'.format(FN))\n",
    "                #print('True Positives\\n {}'.format(TP))\n",
    "                #print('True Negetives\\n {}'.format(TN))\n",
    "                TPR = TP/(TP+FN)\n",
    "                print('Sensitivity \\n {}'.format(TPR))\n",
    "                TNR = TN/(TN+FP)\n",
    "                print('Specificity \\n {}'.format(TNR))\n",
    "                Precision = TP/(TP+FP)\n",
    "                print('Precision \\n {}'.format(Precision))\n",
    "                Recall = TP/(TP+FN)\n",
    "                print('Recall \\n {}'.format(Recall))\n",
    "                Acc = (TP+TN)/(TP+TN+FP+FN)\n",
    "                #print('√Åccuracy \\n{}'.format(Acc))\n",
    "                Fscore = 2*(Precision*Recall)/(Precision+Recall)\n",
    "                print('FScore \\n{}'.format(Fscore))\n",
    "                scores.append(accuracy)\n",
    "                Nfold+=1\n",
    "                print('\\n\\n')\n",
    "        #plt.plot(epoch, accuarcy, label = \"line 1\")\n",
    "        #print(epoch)\n",
    "        #print(accuarcy)\n",
    "        return (scores,epoch,accuarcy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy percentage\n",
    "def accuracy_met(actual, predicted):\n",
    "        correct = 0\n",
    "        for i in range(len(actual)):\n",
    "                if actual[i] == predicted[i]:\n",
    "                        correct += 1\n",
    "        return correct / float(len(actual)) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Backprop on Seeds dataset\n",
    "seed(1)\n",
    "\n",
    "# evaluate algorithm\n",
    "n_folds = 5\n",
    "l_rate = 0.1\n",
    "mu=0.001\n",
    "n_epoch = 300\n",
    "n_hidden = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Fold 1 results:\n",
      "Confusion Matrix:\n",
      "  11   0   0\n",
      "   0   7   1\n",
      "   0   0  11\n",
      "Sensitivity \n",
      " [1.    0.875 1.   ]\n",
      "Specificity \n",
      " [1.         1.         0.94736842]\n",
      "Precision \n",
      " [1.         1.         0.91666667]\n",
      "Recall \n",
      " [1.    0.875 1.   ]\n",
      "FScore \n",
      "[1.         0.93333333 0.95652174]\n",
      "\n",
      "\n",
      "\n",
      "For Fold 2 results:\n",
      "Confusion Matrix:\n",
      "  10   0   0\n",
      "   0   9   2\n",
      "   0   0   9\n",
      "Sensitivity \n",
      " [1.         0.81818182 1.        ]\n",
      "Specificity \n",
      " [1.        1.        0.9047619]\n",
      "Precision \n",
      " [1.         1.         0.81818182]\n",
      "Recall \n",
      " [1.         0.81818182 1.        ]\n",
      "FScore \n",
      "[1.  0.9 0.9]\n",
      "\n",
      "\n",
      "\n",
      "For Fold 3 results:\n",
      "Confusion Matrix:\n",
      "   6   0   0\n",
      "   0  10   0\n",
      "   0   0  14\n",
      "Sensitivity \n",
      " [1. 1. 1.]\n",
      "Specificity \n",
      " [1. 1. 1.]\n",
      "Precision \n",
      " [1. 1. 1.]\n",
      "Recall \n",
      " [1. 1. 1.]\n",
      "FScore \n",
      "[1. 1. 1.]\n",
      "\n",
      "\n",
      "\n",
      "For Fold 4 results:\n",
      "Confusion Matrix:\n",
      "  10   0   0\n",
      "   0   9   1\n",
      "   0   0  10\n",
      "Sensitivity \n",
      " [1.  0.9 1. ]\n",
      "Specificity \n",
      " [1.   1.   0.95]\n",
      "Precision \n",
      " [1.         1.         0.90909091]\n",
      "Recall \n",
      " [1.  0.9 1. ]\n",
      "FScore \n",
      "[1.         0.94736842 0.95238095]\n",
      "\n",
      "\n",
      "\n",
      "For Fold 5 results:\n",
      "Confusion Matrix:\n",
      "  13   0   0\n",
      "   0   7   4\n",
      "   0   0   6\n",
      "Sensitivity \n",
      " [1.         0.63636364 1.        ]\n",
      "Specificity \n",
      " [1.         1.         0.83333333]\n",
      "Precision \n",
      " [1.  1.  0.6]\n",
      "Recall \n",
      " [1.         0.63636364 1.        ]\n",
      "FScore \n",
      "[1.         0.77777778 0.75      ]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores,epoch,accuarcy = run_algorithm(iris_dataset, back_propagation, n_folds, l_rate, n_epoch, n_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'train_accuarcy')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot for epochs vs train accuracy\n",
    "plt.plot(epoch, accuarcy)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('train_accuarcy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[96.66666666666667,\n",
       " 93.33333333333333,\n",
       " 100.0,\n",
       " 96.66666666666667,\n",
       " 86.66666666666667]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy score for different test folds\n",
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
