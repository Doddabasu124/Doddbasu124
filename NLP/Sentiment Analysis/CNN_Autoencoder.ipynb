{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Autoencoder.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYh9LHL5jgR8"
      },
      "source": [
        "# Convolutional Autoencoder-Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEXm_Tp6ZdBj"
      },
      "source": [
        "# import the dependency libraries\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import LeakyReLU, Dense, Flatten, Conv1D, Conv1DTranspose, MaxPooling1D, Input, BatchNormalization, MaxPool1D \n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow_datasets as tfds # To load the datasets\n",
        "import tensorflow_hub as hub       # Used for Transfer learning\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7sJSwUNS1cg"
      },
      "source": [
        "# To know all available datasets in Tensorflow_hub are\n",
        "#tfds.list_builders()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LazHL6qkaMlK"
      },
      "source": [
        "### Download IMBD dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsxV1f4GaBoq"
      },
      "source": [
        "# Load the IMBD data set into (train(80%), Validation(20%)) of 25000 examples and Testdataset(100%) of 25000 examples.\n",
        "train_data, validation_data, test_data = tfds.load(name=\"imdb_reviews\", \n",
        "                                                  split=('train[:80%]', 'train[80%:]', 'test'), # split the dataset into Train, Validation, and Test dataset\n",
        "                                                  as_supervised=True   # Returns tuple structure (input, label)\n",
        "                                                  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qc7aqFh_EYAz",
        "outputId": "5e93b656-dfb1-4d51-d894-55a4f11edf24"
      },
      "source": [
        "#Unpack the train dataset\n",
        "train_examples_batch, train_labels_batch = next(iter(train_data.batch(20000)))\n",
        "\n",
        "#Unpack the validation dataset\n",
        "val_examples_batch, val_labels_batch = next(iter(validation_data.batch(5000)))\n",
        "\n",
        "#Unpack the validation dataset\n",
        "X_test_examples, y_test_labels = next(iter(test_data.batch(25000)))\n",
        "\n",
        "# view some samples of dataset\n",
        "train_examples_batch[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5,), dtype=string, numpy=\n",
              "array([b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\",\n",
              "       b'I have been known to fall asleep during films, but this is usually due to a combination of things including, really tired, being warm and comfortable on the sette and having just eaten a lot. However on this occasion I fell asleep because the film was rubbish. The plot development was constant. Constantly slow and boring. Things seemed to happen, but with no explanation of what was causing them or why. I admit, I may have missed part of the film, but i watched the majority of it and everything just seemed to happen of its own accord without any real concern for anything else. I cant recommend this film at all.',\n",
              "       b'Mann photographs the Alberta Rocky Mountains in a superb fashion, and Jimmy Stewart and Walter Brennan give enjoyable performances as they always seem to do. <br /><br />But come on Hollywood - a Mountie telling the people of Dawson City, Yukon to elect themselves a marshal (yes a marshal!) and to enforce the law themselves, then gunfighters battling it out on the streets for control of the town? <br /><br />Nothing even remotely resembling that happened on the Canadian side of the border during the Klondike gold rush. Mr. Mann and company appear to have mistaken Dawson City for Deadwood, the Canadian North for the American Wild West.<br /><br />Canadian viewers be prepared for a Reefer Madness type of enjoyable howl with this ludicrous plot, or, to shake your head in disgust.',\n",
              "       b'This is the kind of film for a snowy Sunday afternoon when the rest of the world can go ahead with its own business as you descend into a big arm-chair and mellow for a couple of hours. Wonderful performances from Cher and Nicolas Cage (as always) gently row the plot along. There are no rapids to cross, no dangerous waters, just a warm and witty paddle through New York life at its best. A family film in every sense and one that deserves the praise it received.',\n",
              "       b'As others have mentioned, all the women that go nude in this film are mostly absolutely gorgeous. The plot very ably shows the hypocrisy of the female libido. When men are around they want to be pursued, but when no \"men\" are around, they become the pursuers of a 14 year old boy. And the boy becomes a man really fast (we should all be so lucky at this age!). He then gets up the courage to pursue his true love.'],\n",
              "      dtype=object)>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKmx31t-I84D",
        "outputId": "428cd80c-d63d-4c6e-b3c7-6230dfea77d7"
      },
      "source": [
        "next(iter(train_data.shuffle(5).batch(2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(2,), dtype=string, numpy=\n",
              " array([b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\",\n",
              "        b'As others have mentioned, all the women that go nude in this film are mostly absolutely gorgeous. The plot very ably shows the hypocrisy of the female libido. When men are around they want to be pursued, but when no \"men\" are around, they become the pursuers of a 14 year old boy. And the boy becomes a man really fast (we should all be so lucky at this age!). He then gets up the courage to pursue his true love.'],\n",
              "       dtype=object)>,\n",
              " <tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 1])>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yK5k_OXBaBwW",
        "outputId": "0422fd65-980d-4e93-9b0c-4e9330b837dd"
      },
      "source": [
        "# view some label dataset\n",
        "train_labels_batch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20000,), dtype=int64, numpy=array([0, 0, 0, ..., 0, 0, 0])>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_rnuzAjvLTY"
      },
      "source": [
        "### Word Embedding\n",
        "One way to represent the text is to convert sentences into embeddings vectors. Use a pre-trained text embedding as the first layer, which will have three advantages:\n",
        "\n",
        "* You don't have to worry about text preprocessing,\n",
        "* Benefit from transfer learning,\n",
        "* the embedding has a fixed size, so it's simpler to process.\n",
        "\n",
        "Here we use **nnlm-en-dim50** pretrained module for token based text embedding which is trained on English Google News 7B corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dI3JAYBIaB0t"
      },
      "source": [
        "# Load the pretrained module to encode the text dataset\n",
        "embed = hub.load(\"https://tfhub.dev/google/nnlm-en-dim50/2\")\n",
        "\n",
        "# create Hub layer which converts text into embedding vector\n",
        "hub_layer = hub.KerasLayer(embed, input_shape=[], # Expects a tensor of shape [batch_size] as input.\n",
        "                           dtype=tf.string,       # Expects a tf.string input tensor.\n",
        "                           trainable=False        # Make Embedding as trainable\n",
        "                           )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHFp6-QrwZOM",
        "outputId": "190fe1af-f06a-420b-8f67-a05fb2f7e801"
      },
      "source": [
        "# embedding of train dataset\n",
        "Xembd_layer = hub_layer(train_examples_batch)\n",
        "\n",
        "# embedding of validation dataset\n",
        "val_emb_dataset = hub_layer(val_examples_batch)\n",
        "\n",
        "# embedding test dataset\n",
        "test_emb_dataset = hub_layer(X_test_examples)\n",
        "\n",
        "#shape of train dataset\n",
        "print(Xembd_layer.shape)\n",
        "\n",
        "#shape of validation dataset\n",
        "print(val_emb_dataset.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 50)\n",
            "(5000, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6n2NPFG4kZyo",
        "outputId": "858a21af-d225-46c9-ffe0-a13dc421b15a"
      },
      "source": [
        "# View some samples of Embedded training dataset\n",
        "Xembd_layer[:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 50), dtype=float32, numpy=\n",
              "array([[ 0.5423195 , -0.0119017 ,  0.06337538,  0.06862972, -0.16776837,\n",
              "        -0.10581174,  0.16865303, -0.04998824, -0.31148055,  0.07910346,\n",
              "         0.15442263,  0.01488662,  0.03930153,  0.19772711, -0.12215476,\n",
              "        -0.04120981, -0.2704109 , -0.21922152,  0.26517662, -0.80739075,\n",
              "         0.25833532, -0.3100421 ,  0.28683215,  0.1943387 , -0.29036492,\n",
              "         0.03862849, -0.7844411 , -0.0479324 ,  0.4110299 , -0.36388892,\n",
              "        -0.58034706,  0.30269456,  0.3630897 , -0.15227164, -0.44391504,\n",
              "         0.19462997,  0.19528408,  0.05666234,  0.2890704 , -0.28468323,\n",
              "        -0.00531206,  0.0571938 , -0.3201318 , -0.04418665, -0.08550783,\n",
              "        -0.55847436, -0.23336391, -0.20782952, -0.03543064, -0.17533456],\n",
              "       [ 0.56338924, -0.12339553, -0.10862679,  0.7753425 , -0.07667089,\n",
              "        -0.15752277,  0.01872335, -0.08169781, -0.3521876 ,  0.4637341 ,\n",
              "        -0.08492756,  0.07166859, -0.00670817,  0.12686075, -0.19326553,\n",
              "        -0.52626437, -0.3295823 ,  0.14394785,  0.09043556, -0.5417555 ,\n",
              "         0.02468163, -0.15456742,  0.68333143,  0.09068331, -0.45327246,\n",
              "         0.23180096, -0.8615696 ,  0.34480393,  0.12838456, -0.58759046,\n",
              "        -0.4071231 ,  0.23061076,  0.48426893, -0.27128142, -0.5380916 ,\n",
              "         0.47016326,  0.22572741, -0.00830663,  0.2846242 , -0.304985  ,\n",
              "         0.04400365,  0.25025874,  0.14867121,  0.40717036, -0.15422426,\n",
              "        -0.06878027, -0.40825695, -0.3149215 ,  0.09283665, -0.20183425]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feZU3fz-0eql"
      },
      "source": [
        "Here Each sentance is represented into 50 dimensional vectors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POcDA3qVB6AL"
      },
      "source": [
        "### Reshape Train_Dataset\n",
        "As you might remember, Conv1D layer expects input shape in 3D as\n",
        "\n",
        "[batch_size, time_steps, input_dimension]\n",
        "\n",
        "However, current data is in the shape of\n",
        "\n",
        "[batch_size, features]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRqIr6v2ByRs",
        "outputId": "d6cce671-6158-43aa-903f-42ea86ea0547"
      },
      "source": [
        "SAMPLE_SIZE = Xembd_layer.shape[0] # number of samples in train set\n",
        "TIMESTEPS  = Xembd_layer.shape[1] # number of features in train set\n",
        "N_FEATURES = 1               # each feature is represented by 1 number\n",
        "\n",
        "#Reshape the dataset\n",
        "train_data_reshaped = tf.reshape(Xembd_layer, [SAMPLE_SIZE,TIMESTEPS,N_FEATURES])\n",
        "\n",
        "print(\"After reshape train data set shape: \", train_data_reshaped.shape)\n",
        "print(\"1 Sample shape: \",Xembd_layer[0].shape)\n",
        "print(\"An example sample:\\n\", Xembd_layer[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After reshape train data set shape:  (20000, 50, 1)\n",
            "1 Sample shape:  (50,)\n",
            "An example sample:\n",
            " tf.Tensor(\n",
            "[ 0.5423195  -0.0119017   0.06337538  0.06862972 -0.16776837 -0.10581174\n",
            "  0.16865303 -0.04998824 -0.31148055  0.07910346  0.15442263  0.01488662\n",
            "  0.03930153  0.19772711 -0.12215476 -0.04120981 -0.2704109  -0.21922152\n",
            "  0.26517662 -0.80739075  0.25833532 -0.3100421   0.28683215  0.1943387\n",
            " -0.29036492  0.03862849 -0.7844411  -0.0479324   0.4110299  -0.36388892\n",
            " -0.58034706  0.30269456  0.3630897  -0.15227164 -0.44391504  0.19462997\n",
            "  0.19528408  0.05666234  0.2890704  -0.28468323 -0.00531206  0.0571938\n",
            " -0.3201318  -0.04418665 -0.08550783 -0.55847436 -0.23336391 -0.20782952\n",
            " -0.03543064 -0.17533456], shape=(50,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rK-90SSbsMlb"
      },
      "source": [
        "### Reshape the validation dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p04NcLcXpzVh",
        "outputId": "b1c2a2a8-6f24-4fd0-d8c5-80f56647e6ae"
      },
      "source": [
        "# We need to reshape the validation dataset as well\n",
        "val_SAMPLE_SIZE = val_emb_dataset.shape[0] # number of samples in train set\n",
        "val_TIMESTEPS  = val_emb_dataset.shape[1]  # number of features in train set\n",
        "val_N_FEATURES = 1                     # each feature is represented by 1 number\n",
        "\n",
        "#Reshape the dataset\n",
        "val_data_reshaped = tf.reshape(val_emb_dataset, [val_SAMPLE_SIZE, val_TIMESTEPS, val_N_FEATURES])\n",
        "\n",
        "print(\"After reshape train data set shape: \", val_data_reshaped.shape)\n",
        "print(\"1 Sample shape: \",val_emb_dataset[0].shape)\n",
        "print(\"An example sample:\\n\", val_emb_dataset[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After reshape train data set shape:  (5000, 50, 1)\n",
            "1 Sample shape:  (50,)\n",
            "An example sample:\n",
            " tf.Tensor(\n",
            "[ 9.7111344e-01  8.3876096e-02 -2.3345542e-01  4.0072110e-01\n",
            "  5.3514248e-01 -3.3430302e-01  5.8403976e-02 -4.5053214e-02\n",
            " -2.8198385e-01  7.9080468e-01  1.9627273e-01  2.4578339e-01\n",
            "  1.3954996e-05  2.4302465e-01 -4.9030185e-01 -1.0163963e-01\n",
            " -2.9281303e-01  1.9660410e-01 -5.2004270e-02 -8.1745976e-01\n",
            " -6.7622498e-02 -2.1134062e-01  4.1776115e-01 -1.1303243e-01\n",
            " -2.8801519e-01  3.5838264e-01 -1.2306654e+00  2.4650088e-01\n",
            "  2.4441591e-01 -5.1148921e-01 -2.3490804e-01  3.8145795e-01\n",
            "  5.3663242e-01 -4.3924636e-01 -3.4829819e-01  3.6493841e-01\n",
            " -1.6470081e-01 -2.0877215e-01  1.1981481e-01 -6.7716628e-01\n",
            "  5.5227824e-03  3.5140291e-01 -4.3553081e-01  3.0726346e-01\n",
            " -2.0936011e-01  4.8649479e-02 -2.9413393e-01 -4.4267365e-01\n",
            "  2.0608190e-02 -6.8088852e-02], shape=(50,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ijEyEl3ZiYu"
      },
      "source": [
        "### Reshape test_Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZLm6Ma2TvRp",
        "outputId": "3d369173-b1af-4930-8952-9745c2451a7f"
      },
      "source": [
        "SAMPLE_SIZE = test_emb_dataset.shape[0] # number of samples in train set\n",
        "TIMESTEPS  = test_emb_dataset.shape[1] # number of features in train set\n",
        "N_FEATURES = 1               # each feature is represented by 1 number\n",
        "\n",
        "#Reshape the dataset\n",
        "test_data_reshaped = tf.reshape(test_emb_dataset, [SAMPLE_SIZE,TIMESTEPS,N_FEATURES])\n",
        "\n",
        "print(\"After reshape train data set shape: \", test_data_reshaped.shape)\n",
        "print(\"1 Sample shape: \",test_emb_dataset[0].shape)\n",
        "print(\"An example sample:\\n\", test_emb_dataset[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After reshape train data set shape:  (25000, 50, 1)\n",
            "1 Sample shape:  (50,)\n",
            "An example sample:\n",
            " tf.Tensor(\n",
            "[ 0.6750989   0.20966221 -0.24682619  0.70157504  0.00509059 -0.04043961\n",
            " -0.13563964  0.15544751 -0.6535283   0.24198306 -0.14894551 -0.00701114\n",
            " -0.28954473  0.2347527  -0.07211338 -0.26374155 -0.2103376   0.19537686\n",
            "  0.20801611 -0.53941184  0.09185641 -0.23350327  0.4647283   0.02278872\n",
            " -0.4248397  -0.3470194  -0.5100059  -0.0632058   0.11524688 -0.36703324\n",
            " -0.4015741   0.22107722  0.0946885  -0.21738936 -0.31970024  0.4252959\n",
            "  0.44440353  0.04942252  0.23904411 -0.48945317 -0.06317567  0.07366529\n",
            " -0.2791622   0.02657618 -0.24505381 -0.11724484 -0.2243641  -0.04366887\n",
            "  0.10280503  0.18705933], shape=(50,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_22JK01039H"
      },
      "source": [
        "## Model Building:\n",
        "Model Building by using Convolutional Autoencoder-Classifier\n",
        "\n",
        "* An autoencoder is composed of an encoder and a decoder sub-models. The encoder compresses the input and the decoder attempts to recreate the input from the compressed version provided by the encoder. After training, the encoder model is saved and the decoder is discarded.\n",
        "* There are mainly 3 ways to force the autoencoder to learn useful features:\n",
        "  1. **keeping the code size small** : Keeping the code layer small forced our autoencoder to learn an intelligent representation of the data\n",
        "  2. **Denoising Autoencoders**: Adding random noise to its inputs and making it recover the original noise-free data. This way the autoencoder can’t simply copy the input to its output because the input also contains random noise. We are asking it to subtract the noise and produce the underlying meaningful data.\n",
        "  3. **Sparse Autoencoder**: A sparse autoencoder is simply an autoencoder whose training criterion involves a sparsity penalty. In most cases, we would construct our loss function by penalizing activations of hidden layers so that only a few nodes are encouraged to activate when a single sample is fed into the network\n",
        "\n",
        "For this example we use Sparse Autoencoder method to build a model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQth67480ypF"
      },
      "source": [
        "# Sparse convolutional autoencoder\n",
        "\n",
        "inputs = Input(shape=(TIMESTEPS, N_FEATURES), name ='encoder_input')\n",
        "\n",
        "# Encoder Function \n",
        "def encoder ( inp ):\n",
        "\n",
        "  #1st layer of encoder of Conv1D should have same units should have number of input dimension\n",
        "  conv1 = Conv1D(filters = N_FEATURES, kernel_size =3, padding='same',activation='relu', name= 'encoder-conv1')(inp)\n",
        "  \n",
        "  #act = LeakyReLU(alpha=0.1)(conv1)\n",
        "  #norm = BatchNormalization()(act)\n",
        "  #conv2 = Conv1D(filters = N_FEATURES, kernel_size =3, padding='same', name= 'encoder-conv2')(norm)\n",
        "  #act2 = LeakyReLU(alpha=0.1)(conv1)\n",
        "  #norm = BatchNormalization()(act2)\n",
        "\n",
        "  # Add pooling layer\n",
        "  pool1 = MaxPool1D(pool_size=3, strides=1, padding='same', name='encoder-pool1')(conv1)\n",
        "\n",
        "  # Encoding layer\n",
        "  encoding = Dense(units=N_FEATURES, # Note: we can also change the nerons in this layer\n",
        "                   activation='linear',\n",
        "                   activity_regularizer = tf.keras.regularizers.L1( l1 = 0.01), # Add regulizer term to this layer to get sparsity \n",
        "                   name = 'encoder-dense')(pool1)\n",
        " \n",
        "\n",
        "  # now return the encoding values\n",
        "  return encoding\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRRwPYPS44CE",
        "outputId": "201c80dd-e90b-4c68-fc89-8dd0c368a784"
      },
      "source": [
        "encode = Model(inputs = inputs, outputs=encoder(inputs))\n",
        "encode.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   [(None, 50, 1)]           0         \n",
            "_________________________________________________________________\n",
            "encoder-conv1 (Conv1D)       (None, 50, 1)             4         \n",
            "_________________________________________________________________\n",
            "encoder-pool1 (MaxPooling1D) (None, 50, 1)             0         \n",
            "_________________________________________________________________\n",
            "encoder-dense (Dense)        (None, 50, 1)             2         \n",
            "=================================================================\n",
            "Total params: 6\n",
            "Trainable params: 6\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAqrDrBH8y4T",
        "outputId": "40e4ba65-7121-4da6-d50c-b4aa886d3f95"
      },
      "source": [
        "# lets see the outputs values of encoder model by taking 1 sample example\n",
        "encode.predict(test_data_reshaped[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 50, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 50, 1), dtype=tf.float32, name='encoder_input'), name='encoder_input', description=\"created by layer 'encoder_input'\"), but it was called on an input with incompatible shape (None, 1, 1).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 50, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 50, 1), dtype=tf.float32, name='encoder_input'), name='encoder_input', description=\"created by layer 'encoder_input'\"), but it was called on an input with incompatible shape (None, 1, 1).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.        ]],\n",
              "\n",
              "       [[0.        ]],\n",
              "\n",
              "       [[0.12213753]],\n",
              "\n",
              "       [[0.        ]],\n",
              "\n",
              "       [[0.        ]],\n",
              "\n",
              "       [[0.02001082]],\n",
              "\n",
              "       [[0.06711885]],\n",
              "\n",
              "       [[0.        ]],\n",
              "\n",
              "       [[0.32338682]],\n",
              "\n",
              "       [[0.        ]],\n",
              "\n",
              "       [[0.07370303]],\n",
              "\n",
              "       [[0.00346934]],\n",
              "\n",
              "       [[0.14327604]],\n",
              "\n",
              "       [[0.        ]],\n",
              "\n",
              "       [[0.03568402]],\n",
              "\n",
              "       [[0.1305078 ]],\n",
              "\n",
              "       [[0.10408179]],\n",
              "\n",
              "       [[0.        ]],\n",
              "\n",
              "       [[0.        ]],\n",
              "\n",
              "       [[0.26691833]],\n",
              "\n",
              "       [[0.        ]],\n",
              "\n",
              "       [[0.11554492]],\n",
              "\n",
              "       [[0.        ]],\n",
              "\n",
              "       [[0.        ]],\n",
              "\n",
              "       [[0.21022435]],\n",
              "\n",
              "       [[0.17171636]],\n",
              "\n",
              "       [[0.2523673 ]],\n",
              "\n",
              "       [[0.03127626]],\n",
              "\n",
              "       [[0.        ]],\n",
              "\n",
              "       [[0.18161985]],\n",
              "\n",
              "       [[0.19871178]],\n",
              "\n",
              "       [[0.        ]],\n",
              "\n",
              "       [[0.        ]],\n",
              "\n",
              "       [[0.10757124]],\n",
              "\n",
              "       [[0.15819795]],\n",
              "\n",
              "       [[0.        ]],\n",
              "\n",
              "       [[0.        ]],\n",
              "\n",
              "       [[0.        ]],\n",
              "\n",
              "       [[0.        ]],\n",
              "\n",
              "       [[0.24219716]],\n",
              "\n",
              "       [[0.03126135]],\n",
              "\n",
              "       [[0.        ]],\n",
              "\n",
              "       [[0.13813843]],\n",
              "\n",
              "       [[0.        ]],\n",
              "\n",
              "       [[0.12126051]],\n",
              "\n",
              "       [[0.05801652]],\n",
              "\n",
              "       [[0.11102258]],\n",
              "\n",
              "       [[0.02160876]],\n",
              "\n",
              "       [[0.        ]],\n",
              "\n",
              "       [[0.        ]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X03fz3nlMb9U"
      },
      "source": [
        "Inference : We can see that, The prediction of encoder is Sparse matric. This is caused due to adding regularization method in last layer of encoder where it penalize the less important values for prdiction to zeros."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiqe_wtfLG-5"
      },
      "source": [
        "# Decoder Function\n",
        "def decoder(encoding):\n",
        "  # add Transpose Convolution layer to convolve and upsample the Encoder output to reconstruct back the original inputs back.\n",
        "  convT1 = Conv1DTranspose(filters=N_FEATURES, kernel_size=3, activation='linear', padding='same')(encoding)\n",
        "\n",
        "  #applying BatchNormalization to prevent from exploding gradients                 \n",
        "  #decoding = BatchNormalization()(convT1)\n",
        "\n",
        "  #conv11 = Conv1D(filters = 2, kernel_size =3, padding='same',activation='relu', name= 'encoder-conv11')(decoding)\n",
        "\n",
        "  #pool11 = MaxPool1D(pool_size=2, strides=1, padding='same', name='encoder-pool11')(convT1)\n",
        "\n",
        "  decoding = BatchNormalization()(convT1)\n",
        "\n",
        "  # final layer of decoder\n",
        "  decoding = Dense(units=N_FEATURES, \n",
        "                   activation ='linear')(decoding)\n",
        "\n",
        "  return decoding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Z4fcCLw5K-V",
        "outputId": "833e46ab-50d4-43e3-9bdf-ee18f0dab2cf"
      },
      "source": [
        "# Group layers of encoder and decoder into an object with training and inference features.\n",
        "autoencoder = Model(inputs=inputs, outputs = decoder(encoder(inputs)))\n",
        "\n",
        "#Get the summary of Autoencoder\n",
        "autoencoder.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   [(None, 50, 1)]           0         \n",
            "_________________________________________________________________\n",
            "encoder-conv1 (Conv1D)       (None, 50, 1)             4         \n",
            "_________________________________________________________________\n",
            "encoder-pool1 (MaxPooling1D) (None, 50, 1)             0         \n",
            "_________________________________________________________________\n",
            "encoder-dense (Dense)        (None, 50, 1)             2         \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 50, 1)             4         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 50, 1)             4         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 50, 1)             2         \n",
            "=================================================================\n",
            "Total params: 16\n",
            "Trainable params: 14\n",
            "Non-trainable params: 2\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kQJrZ0hzeoB",
        "outputId": "d11e8c3c-ffb0-4c4f-d295-8ffad063b173"
      },
      "source": [
        "# autoencoder model compilation \n",
        "autoencoder.compile(loss = 'mean_squared_error',  optimizer='adam', metrics=['mean_absolute_error'])\n",
        "\n",
        "# Train the model\n",
        "history = autoencoder.fit(x =train_data_reshaped, y=train_data_reshaped, epochs=50, batch_size=150, \n",
        "                          validation_data=(val_data_reshaped, val_data_reshaped), \n",
        "                          verbose=1).history"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "134/134 [==============================] - 2s 11ms/step - loss: 2.2358 - mean_absolute_error: 1.0836 - val_loss: 0.5262 - val_mean_absolute_error: 0.4441\n",
            "Epoch 2/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 1.3175 - mean_absolute_error: 0.8222 - val_loss: 0.3999 - val_mean_absolute_error: 0.4444\n",
            "Epoch 3/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.7578 - mean_absolute_error: 0.5936 - val_loss: 0.2507 - val_mean_absolute_error: 0.3291\n",
            "Epoch 4/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.2681 - mean_absolute_error: 0.3461 - val_loss: 0.1861 - val_mean_absolute_error: 0.3188\n",
            "Epoch 5/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1803 - mean_absolute_error: 0.3181 - val_loss: 0.1790 - val_mean_absolute_error: 0.3170\n",
            "Epoch 6/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1761 - mean_absolute_error: 0.3152 - val_loss: 0.1738 - val_mean_absolute_error: 0.3122\n",
            "Epoch 7/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1732 - mean_absolute_error: 0.3112 - val_loss: 0.1720 - val_mean_absolute_error: 0.3083\n",
            "Epoch 8/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1705 - mean_absolute_error: 0.3065 - val_loss: 0.1704 - val_mean_absolute_error: 0.3048\n",
            "Epoch 9/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1682 - mean_absolute_error: 0.3017 - val_loss: 0.1697 - val_mean_absolute_error: 0.3011\n",
            "Epoch 10/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1664 - mean_absolute_error: 0.2979 - val_loss: 0.1669 - val_mean_absolute_error: 0.2967\n",
            "Epoch 11/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1648 - mean_absolute_error: 0.2948 - val_loss: 0.1642 - val_mean_absolute_error: 0.2932\n",
            "Epoch 12/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1631 - mean_absolute_error: 0.2923 - val_loss: 0.1655 - val_mean_absolute_error: 0.2931\n",
            "Epoch 13/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1612 - mean_absolute_error: 0.2897 - val_loss: 0.1626 - val_mean_absolute_error: 0.2925\n",
            "Epoch 14/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1589 - mean_absolute_error: 0.2872 - val_loss: 0.1578 - val_mean_absolute_error: 0.2858\n",
            "Epoch 15/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1561 - mean_absolute_error: 0.2840 - val_loss: 0.1547 - val_mean_absolute_error: 0.2827\n",
            "Epoch 16/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1516 - mean_absolute_error: 0.2783 - val_loss: 0.1592 - val_mean_absolute_error: 0.2938\n",
            "Epoch 17/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1430 - mean_absolute_error: 0.2697 - val_loss: 0.1500 - val_mean_absolute_error: 0.2887\n",
            "Epoch 18/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1340 - mean_absolute_error: 0.2662 - val_loss: 0.1490 - val_mean_absolute_error: 0.2919\n",
            "Epoch 19/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1297 - mean_absolute_error: 0.2648 - val_loss: 0.1411 - val_mean_absolute_error: 0.2807\n",
            "Epoch 20/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1268 - mean_absolute_error: 0.2623 - val_loss: 0.1303 - val_mean_absolute_error: 0.2655\n",
            "Epoch 21/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1244 - mean_absolute_error: 0.2585 - val_loss: 0.1302 - val_mean_absolute_error: 0.2633\n",
            "Epoch 22/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1207 - mean_absolute_error: 0.2525 - val_loss: 0.1188 - val_mean_absolute_error: 0.2513\n",
            "Epoch 23/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1171 - mean_absolute_error: 0.2502 - val_loss: 0.1176 - val_mean_absolute_error: 0.2511\n",
            "Epoch 24/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1161 - mean_absolute_error: 0.2507 - val_loss: 0.1164 - val_mean_absolute_error: 0.2510\n",
            "Epoch 25/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1154 - mean_absolute_error: 0.2509 - val_loss: 0.1167 - val_mean_absolute_error: 0.2537\n",
            "Epoch 26/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1149 - mean_absolute_error: 0.2510 - val_loss: 0.1148 - val_mean_absolute_error: 0.2507\n",
            "Epoch 27/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1144 - mean_absolute_error: 0.2510 - val_loss: 0.1154 - val_mean_absolute_error: 0.2531\n",
            "Epoch 28/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1140 - mean_absolute_error: 0.2509 - val_loss: 0.1140 - val_mean_absolute_error: 0.2508\n",
            "Epoch 29/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1137 - mean_absolute_error: 0.2509 - val_loss: 0.1331 - val_mean_absolute_error: 0.2806\n",
            "Epoch 30/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1133 - mean_absolute_error: 0.2508 - val_loss: 0.1198 - val_mean_absolute_error: 0.2576\n",
            "Epoch 31/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1130 - mean_absolute_error: 0.2508 - val_loss: 0.1129 - val_mean_absolute_error: 0.2504\n",
            "Epoch 32/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1127 - mean_absolute_error: 0.2507 - val_loss: 0.1835 - val_mean_absolute_error: 0.3356\n",
            "Epoch 33/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1124 - mean_absolute_error: 0.2507 - val_loss: 0.1680 - val_mean_absolute_error: 0.3179\n",
            "Epoch 34/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1121 - mean_absolute_error: 0.2506 - val_loss: 0.1163 - val_mean_absolute_error: 0.2546\n",
            "Epoch 35/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1119 - mean_absolute_error: 0.2506 - val_loss: 0.1414 - val_mean_absolute_error: 0.2859\n",
            "Epoch 36/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1117 - mean_absolute_error: 0.2506 - val_loss: 0.1158 - val_mean_absolute_error: 0.2577\n",
            "Epoch 37/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1114 - mean_absolute_error: 0.2505 - val_loss: 0.1232 - val_mean_absolute_error: 0.2637\n",
            "Epoch 38/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1112 - mean_absolute_error: 0.2505 - val_loss: 0.1197 - val_mean_absolute_error: 0.2594\n",
            "Epoch 39/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1110 - mean_absolute_error: 0.2505 - val_loss: 0.1285 - val_mean_absolute_error: 0.2775\n",
            "Epoch 40/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1108 - mean_absolute_error: 0.2504 - val_loss: 0.1244 - val_mean_absolute_error: 0.2713\n",
            "Epoch 41/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1106 - mean_absolute_error: 0.2504 - val_loss: 0.1218 - val_mean_absolute_error: 0.2689\n",
            "Epoch 42/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1105 - mean_absolute_error: 0.2504 - val_loss: 0.2008 - val_mean_absolute_error: 0.3679\n",
            "Epoch 43/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1103 - mean_absolute_error: 0.2504 - val_loss: 0.1125 - val_mean_absolute_error: 0.2519\n",
            "Epoch 44/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1101 - mean_absolute_error: 0.2504 - val_loss: 0.1175 - val_mean_absolute_error: 0.2576\n",
            "Epoch 45/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1100 - mean_absolute_error: 0.2504 - val_loss: 0.1178 - val_mean_absolute_error: 0.2629\n",
            "Epoch 46/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1098 - mean_absolute_error: 0.2503 - val_loss: 0.1195 - val_mean_absolute_error: 0.2611\n",
            "Epoch 47/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1097 - mean_absolute_error: 0.2503 - val_loss: 0.1201 - val_mean_absolute_error: 0.2621\n",
            "Epoch 48/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1096 - mean_absolute_error: 0.2503 - val_loss: 0.2030 - val_mean_absolute_error: 0.3617\n",
            "Epoch 49/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1094 - mean_absolute_error: 0.2503 - val_loss: 0.1806 - val_mean_absolute_error: 0.3368\n",
            "Epoch 50/50\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1093 - mean_absolute_error: 0.2503 - val_loss: 0.1277 - val_mean_absolute_error: 0.2714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoPZILSvO-51"
      },
      "source": [
        "### Convolutional Classifier Initialized with Encoder\n",
        "A classifier can be (potentially) enhanced with an autoencoder. Listing constructs a feed-forward convolutional classifier with an encoder\n",
        "attached to it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubHQ4rzeNtbx"
      },
      "source": [
        "#  CNN Classifier initialized with Encoder\n",
        "def fully_connected ( encoding ):\n",
        "  # convolution 1d layer\n",
        "  conv1 = Conv1D(filters =20, kernel_size=3, activation='relu' ,padding='valid', name = 'fc-con1')(encoding)\n",
        "\n",
        "  #conv2 = Conv1D(filters =20, kernel_size=3, padding='valid', activation='relu', name = 'fc-con2')(conv1)\n",
        "\n",
        "  # Pooling layer\n",
        "  pool1 = MaxPool1D(pool_size=2, padding='valid', name ='fc-pool1')(conv1)\n",
        "  \n",
        "  #flatten the output of pooling layer\n",
        "  flat1 = Flatten()(pool1)\n",
        "   \n",
        "  #Dense layer\n",
        "  den = Dense(units=20, activation='relu')(flat1)\n",
        "   \n",
        "  # output layer\n",
        "  output = Dense ( units =1, activation='sigmoid', name = 'output')(den)\n",
        "\n",
        "  return(output)\n",
        "\n",
        "encoding = encoder(inputs)\n",
        "\n",
        "# Combine encoder(trained encoder) and fullyconnected models to get final output\n",
        "Classifier = Model(inputs = inputs, outputs= fully_connected(encoding=encoder(inputs)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1NIHPDzVBvJ"
      },
      "source": [
        "The encoder can be used to have either a,\n",
        "  * Pre-trained classifier. A trained encoder can be used as a part\n",
        "of a feed-forward classifier network. Or,\n",
        "  * Encoded features as input. The features produced by an encoder used as     input to a classifier.\n",
        "\n",
        "Corresponding to the two approaches, an argument retrain_encoding\n",
        "is defined in Listing.\n",
        "The argument when set to False results in the classifier using the\n",
        "encoded features as input. This is achieved by making the layers in the encoder section of the model as non-trainable in line 13 in the listing.\n",
        "The argument, retrain_encoding, when set to True uses the encoding weights to initialize the model and retrain them while learning\n",
        "the classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28E-nOABXEpB",
        "outputId": "10597f32-b90c-4d34-9aa3-91bec35b53f8"
      },
      "source": [
        "# layers in Classifer model\n",
        "Classifier.layers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.engine.input_layer.InputLayer at 0x7fe068fb0150>,\n",
              " <keras.layers.convolutional.Conv1D at 0x7fe066d65490>,\n",
              " <keras.layers.pooling.MaxPooling1D at 0x7fe066d6c450>,\n",
              " <keras.layers.core.Dense at 0x7fe0697cf110>,\n",
              " <keras.layers.convolutional.Conv1D at 0x7fe0697e8ed0>,\n",
              " <keras.layers.pooling.MaxPooling1D at 0x7fe06858ded0>,\n",
              " <keras.layers.core.Flatten at 0x7fe066d7cfd0>,\n",
              " <keras.layers.core.Dense at 0x7fe06859e890>,\n",
              " <keras.layers.core.Dense at 0x7fe06859e250>]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfkaAiJaWRUQ",
        "outputId": "57f59145-b860-4f2f-adef-ea5b652ff143"
      },
      "source": [
        "# layers in Autoencoders\n",
        "autoencoder.layers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.engine.input_layer.InputLayer at 0x7fe068fb0150>,\n",
              " <keras.layers.convolutional.Conv1D at 0x7fe068dcea90>,\n",
              " <keras.layers.pooling.MaxPooling1D at 0x7fe068e17310>,\n",
              " <keras.layers.core.Dense at 0x7fe068e36110>,\n",
              " <keras.layers.convolutional.Conv1DTranspose at 0x7fe068e36f90>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fe068dda610>,\n",
              " <keras.layers.core.Dense at 0x7fe068e09850>]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fh-LzHhgcvhl",
        "outputId": "ec267af5-09d9-4c36-d4f4-c28d2fcacede"
      },
      "source": [
        "# Classifier layer initialized with encoder\n",
        "retrain_encoding = False\n",
        "\n",
        "# loop through every layers in classifier model\n",
        "for classifier_layer in Classifier.layers : \n",
        "\n",
        "  # loop through every layers in autoencoder model\n",
        "  for autoencoder_layer in autoencoder.layers:\n",
        "\n",
        "    # Get the name of common layers(i.e, Encoder layers) \n",
        "    if classifier_layer.name == autoencoder_layer.name:\n",
        "\n",
        "      # Set the weights of classifier same as the corresponding autoencoder(encoder) layer\n",
        "      classifier_layer.set_weights(autoencoder_layer.get_weights())\n",
        "\n",
        "      # Only train encoder model if user wants to train the encoder model\n",
        "      if retrain_encoding == False: \n",
        "        # don't train the encoder model layers\n",
        "        classifier_layer.trainable = False\n",
        "\n",
        "        print(classifier_layer.name + 'in classifier set to ' + autoencoder_layer.name + 'in the encoder is trainable:' + \n",
        "              str(classifier_layer.trainable))\n",
        "        \n",
        "Classifier.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder_inputin classifier set to encoder_inputin the encoder is trainable:False\n",
            "encoder-conv1in classifier set to encoder-conv1in the encoder is trainable:False\n",
            "encoder-pool1in classifier set to encoder-pool1in the encoder is trainable:False\n",
            "encoder-densein classifier set to encoder-densein the encoder is trainable:False\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   [(None, 50, 1)]           0         \n",
            "_________________________________________________________________\n",
            "encoder-conv1 (Conv1D)       (None, 50, 1)             4         \n",
            "_________________________________________________________________\n",
            "encoder-pool1 (MaxPooling1D) (None, 50, 1)             0         \n",
            "_________________________________________________________________\n",
            "encoder-dense (Dense)        (None, 50, 1)             2         \n",
            "_________________________________________________________________\n",
            "fc-con1 (Conv1D)             (None, 48, 20)            80        \n",
            "_________________________________________________________________\n",
            "fc-pool1 (MaxPooling1D)      (None, 24, 20)            0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 480)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 20)                9620      \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 21        \n",
            "=================================================================\n",
            "Total params: 9,727\n",
            "Trainable params: 9,721\n",
            "Non-trainable params: 6\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjazMWhhcvbJ"
      },
      "source": [
        "# compile the Classifier model\n",
        "Classifier.compile (optimizer= 'adam', loss= 'binary_crossentropy' , metrics =['accuracy', tf.keras.metrics.Recall()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3n9j3ohUcu7-",
        "outputId": "78d8109a-9a68-4371-c790-1db3137a828c"
      },
      "source": [
        "#Train the model\n",
        "history = Classifier.fit(x =train_data_reshaped, y=train_labels_batch.numpy(), epochs=100, \n",
        "                         validation_data=(val_data_reshaped, val_labels_batch.numpy()), verbose=1).history"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.6673 - accuracy: 0.6132 - recall: 0.6516 - val_loss: 0.6194 - val_accuracy: 0.6750 - val_recall: 0.6713\n",
            "Epoch 2/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.6137 - accuracy: 0.6682 - recall: 0.6499 - val_loss: 0.6011 - val_accuracy: 0.6842 - val_recall: 0.7096\n",
            "Epoch 3/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.6044 - accuracy: 0.6772 - recall: 0.6614 - val_loss: 0.6070 - val_accuracy: 0.6632 - val_recall: 0.8139\n",
            "Epoch 4/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5970 - accuracy: 0.6857 - recall: 0.6731 - val_loss: 0.5979 - val_accuracy: 0.6890 - val_recall: 0.5579\n",
            "Epoch 5/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5927 - accuracy: 0.6887 - recall: 0.6721 - val_loss: 0.5810 - val_accuracy: 0.6960 - val_recall: 0.7183\n",
            "Epoch 6/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5868 - accuracy: 0.6934 - recall: 0.6769 - val_loss: 0.5844 - val_accuracy: 0.6884 - val_recall: 0.8009\n",
            "Epoch 7/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5850 - accuracy: 0.6964 - recall: 0.6826 - val_loss: 0.5820 - val_accuracy: 0.6940 - val_recall: 0.8131\n",
            "Epoch 8/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5798 - accuracy: 0.7002 - recall: 0.6841 - val_loss: 0.5751 - val_accuracy: 0.7046 - val_recall: 0.8005\n",
            "Epoch 9/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5766 - accuracy: 0.7024 - recall: 0.6880 - val_loss: 0.5650 - val_accuracy: 0.7102 - val_recall: 0.7270\n",
            "Epoch 10/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5735 - accuracy: 0.7056 - recall: 0.6932 - val_loss: 0.5647 - val_accuracy: 0.7142 - val_recall: 0.7641\n",
            "Epoch 11/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.5734 - accuracy: 0.7055 - recall: 0.6901 - val_loss: 0.5605 - val_accuracy: 0.7166 - val_recall: 0.7226\n",
            "Epoch 12/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5713 - accuracy: 0.7062 - recall: 0.6956 - val_loss: 0.5641 - val_accuracy: 0.7102 - val_recall: 0.6409\n",
            "Epoch 13/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5676 - accuracy: 0.7096 - recall: 0.6970 - val_loss: 0.5580 - val_accuracy: 0.7182 - val_recall: 0.6993\n",
            "Epoch 14/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5673 - accuracy: 0.7128 - recall: 0.7003 - val_loss: 0.5568 - val_accuracy: 0.7186 - val_recall: 0.7199\n",
            "Epoch 15/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5668 - accuracy: 0.7078 - recall: 0.6974 - val_loss: 0.5566 - val_accuracy: 0.7200 - val_recall: 0.7029\n",
            "Epoch 16/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5653 - accuracy: 0.7114 - recall: 0.6978 - val_loss: 0.5555 - val_accuracy: 0.7192 - val_recall: 0.7440\n",
            "Epoch 17/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5667 - accuracy: 0.7095 - recall: 0.6941 - val_loss: 0.5705 - val_accuracy: 0.7080 - val_recall: 0.8345\n",
            "Epoch 18/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5647 - accuracy: 0.7124 - recall: 0.6983 - val_loss: 0.5549 - val_accuracy: 0.7166 - val_recall: 0.6729\n",
            "Epoch 19/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5652 - accuracy: 0.7109 - recall: 0.6990 - val_loss: 0.5554 - val_accuracy: 0.7172 - val_recall: 0.7780\n",
            "Epoch 20/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5629 - accuracy: 0.7145 - recall: 0.7014 - val_loss: 0.5530 - val_accuracy: 0.7202 - val_recall: 0.7377\n",
            "Epoch 21/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5631 - accuracy: 0.7111 - recall: 0.6997 - val_loss: 0.5554 - val_accuracy: 0.7194 - val_recall: 0.6622\n",
            "Epoch 22/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5623 - accuracy: 0.7143 - recall: 0.7011 - val_loss: 0.5534 - val_accuracy: 0.7218 - val_recall: 0.7412\n",
            "Epoch 23/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5626 - accuracy: 0.7122 - recall: 0.6987 - val_loss: 0.5608 - val_accuracy: 0.7108 - val_recall: 0.8107\n",
            "Epoch 24/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5618 - accuracy: 0.7135 - recall: 0.6965 - val_loss: 0.5507 - val_accuracy: 0.7226 - val_recall: 0.7001\n",
            "Epoch 25/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5608 - accuracy: 0.7165 - recall: 0.7030 - val_loss: 0.5499 - val_accuracy: 0.7252 - val_recall: 0.7218\n",
            "Epoch 26/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5600 - accuracy: 0.7157 - recall: 0.7019 - val_loss: 0.5519 - val_accuracy: 0.7216 - val_recall: 0.6717\n",
            "Epoch 27/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5587 - accuracy: 0.7164 - recall: 0.7036 - val_loss: 0.5503 - val_accuracy: 0.7258 - val_recall: 0.7033\n",
            "Epoch 28/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5594 - accuracy: 0.7168 - recall: 0.6996 - val_loss: 0.5499 - val_accuracy: 0.7234 - val_recall: 0.6855\n",
            "Epoch 29/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5595 - accuracy: 0.7157 - recall: 0.7004 - val_loss: 0.5524 - val_accuracy: 0.7164 - val_recall: 0.6492\n",
            "Epoch 30/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5580 - accuracy: 0.7165 - recall: 0.7023 - val_loss: 0.5481 - val_accuracy: 0.7234 - val_recall: 0.7179\n",
            "Epoch 31/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5585 - accuracy: 0.7157 - recall: 0.7001 - val_loss: 0.5534 - val_accuracy: 0.7204 - val_recall: 0.6424\n",
            "Epoch 32/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5573 - accuracy: 0.7196 - recall: 0.7042 - val_loss: 0.5565 - val_accuracy: 0.7140 - val_recall: 0.6171\n",
            "Epoch 33/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.5575 - accuracy: 0.7162 - recall: 0.6991 - val_loss: 0.5521 - val_accuracy: 0.7192 - val_recall: 0.7866\n",
            "Epoch 34/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5578 - accuracy: 0.7156 - recall: 0.7004 - val_loss: 0.5466 - val_accuracy: 0.7266 - val_recall: 0.7412\n",
            "Epoch 35/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5567 - accuracy: 0.7193 - recall: 0.7059 - val_loss: 0.5520 - val_accuracy: 0.7208 - val_recall: 0.7942\n",
            "Epoch 36/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5556 - accuracy: 0.7179 - recall: 0.7039 - val_loss: 0.5508 - val_accuracy: 0.7206 - val_recall: 0.7851\n",
            "Epoch 37/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5558 - accuracy: 0.7180 - recall: 0.7011 - val_loss: 0.5455 - val_accuracy: 0.7244 - val_recall: 0.7159\n",
            "Epoch 38/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5565 - accuracy: 0.7165 - recall: 0.7000 - val_loss: 0.5472 - val_accuracy: 0.7252 - val_recall: 0.7349\n",
            "Epoch 39/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5543 - accuracy: 0.7212 - recall: 0.7089 - val_loss: 0.5472 - val_accuracy: 0.7246 - val_recall: 0.6812\n",
            "Epoch 40/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5554 - accuracy: 0.7176 - recall: 0.7041 - val_loss: 0.5473 - val_accuracy: 0.7252 - val_recall: 0.6839\n",
            "Epoch 41/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5564 - accuracy: 0.7181 - recall: 0.7024 - val_loss: 0.5470 - val_accuracy: 0.7208 - val_recall: 0.7645\n",
            "Epoch 42/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5537 - accuracy: 0.7172 - recall: 0.7021 - val_loss: 0.5447 - val_accuracy: 0.7262 - val_recall: 0.7444\n",
            "Epoch 43/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5542 - accuracy: 0.7182 - recall: 0.7036 - val_loss: 0.5448 - val_accuracy: 0.7262 - val_recall: 0.7282\n",
            "Epoch 44/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5542 - accuracy: 0.7200 - recall: 0.7055 - val_loss: 0.5440 - val_accuracy: 0.7282 - val_recall: 0.7420\n",
            "Epoch 45/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5535 - accuracy: 0.7185 - recall: 0.7042 - val_loss: 0.5588 - val_accuracy: 0.7176 - val_recall: 0.6061\n",
            "Epoch 46/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.5530 - accuracy: 0.7208 - recall: 0.7052 - val_loss: 0.5461 - val_accuracy: 0.7230 - val_recall: 0.6902\n",
            "Epoch 47/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5518 - accuracy: 0.7200 - recall: 0.7079 - val_loss: 0.5480 - val_accuracy: 0.7240 - val_recall: 0.6653\n",
            "Epoch 48/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5532 - accuracy: 0.7210 - recall: 0.7060 - val_loss: 0.5439 - val_accuracy: 0.7274 - val_recall: 0.7444\n",
            "Epoch 49/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5528 - accuracy: 0.7216 - recall: 0.7076 - val_loss: 0.5441 - val_accuracy: 0.7284 - val_recall: 0.7329\n",
            "Epoch 50/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5523 - accuracy: 0.7202 - recall: 0.7068 - val_loss: 0.5432 - val_accuracy: 0.7280 - val_recall: 0.7317\n",
            "Epoch 51/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5528 - accuracy: 0.7203 - recall: 0.7087 - val_loss: 0.5441 - val_accuracy: 0.7252 - val_recall: 0.7112\n",
            "Epoch 52/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5521 - accuracy: 0.7200 - recall: 0.7063 - val_loss: 0.5452 - val_accuracy: 0.7264 - val_recall: 0.7677\n",
            "Epoch 53/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5509 - accuracy: 0.7204 - recall: 0.7052 - val_loss: 0.5495 - val_accuracy: 0.7238 - val_recall: 0.6464\n",
            "Epoch 54/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5508 - accuracy: 0.7214 - recall: 0.7100 - val_loss: 0.5420 - val_accuracy: 0.7294 - val_recall: 0.7218\n",
            "Epoch 55/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5514 - accuracy: 0.7218 - recall: 0.7075 - val_loss: 0.5425 - val_accuracy: 0.7274 - val_recall: 0.7392\n",
            "Epoch 56/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.5503 - accuracy: 0.7212 - recall: 0.7081 - val_loss: 0.5442 - val_accuracy: 0.7256 - val_recall: 0.7104\n",
            "Epoch 57/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5504 - accuracy: 0.7207 - recall: 0.7071 - val_loss: 0.5576 - val_accuracy: 0.7200 - val_recall: 0.6029\n",
            "Epoch 58/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5498 - accuracy: 0.7224 - recall: 0.7098 - val_loss: 0.5435 - val_accuracy: 0.7262 - val_recall: 0.6946\n",
            "Epoch 59/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5505 - accuracy: 0.7228 - recall: 0.7080 - val_loss: 0.5418 - val_accuracy: 0.7296 - val_recall: 0.7147\n",
            "Epoch 60/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5485 - accuracy: 0.7214 - recall: 0.7100 - val_loss: 0.5438 - val_accuracy: 0.7238 - val_recall: 0.7768\n",
            "Epoch 61/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5499 - accuracy: 0.7209 - recall: 0.7076 - val_loss: 0.5419 - val_accuracy: 0.7296 - val_recall: 0.7238\n",
            "Epoch 62/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5496 - accuracy: 0.7220 - recall: 0.7100 - val_loss: 0.5451 - val_accuracy: 0.7244 - val_recall: 0.7653\n",
            "Epoch 63/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.5488 - accuracy: 0.7211 - recall: 0.7060 - val_loss: 0.5424 - val_accuracy: 0.7302 - val_recall: 0.7112\n",
            "Epoch 64/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5497 - accuracy: 0.7222 - recall: 0.7090 - val_loss: 0.5515 - val_accuracy: 0.7278 - val_recall: 0.6349\n",
            "Epoch 65/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.5487 - accuracy: 0.7233 - recall: 0.7094 - val_loss: 0.5470 - val_accuracy: 0.7198 - val_recall: 0.7863\n",
            "Epoch 66/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5478 - accuracy: 0.7240 - recall: 0.7111 - val_loss: 0.5429 - val_accuracy: 0.7304 - val_recall: 0.7365\n",
            "Epoch 67/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5481 - accuracy: 0.7244 - recall: 0.7119 - val_loss: 0.5436 - val_accuracy: 0.7286 - val_recall: 0.6855\n",
            "Epoch 68/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5488 - accuracy: 0.7229 - recall: 0.7119 - val_loss: 0.5544 - val_accuracy: 0.7248 - val_recall: 0.6148\n",
            "Epoch 69/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5476 - accuracy: 0.7258 - recall: 0.7120 - val_loss: 0.5435 - val_accuracy: 0.7278 - val_recall: 0.7693\n",
            "Epoch 70/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5479 - accuracy: 0.7242 - recall: 0.7104 - val_loss: 0.5404 - val_accuracy: 0.7292 - val_recall: 0.7250\n",
            "Epoch 71/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5474 - accuracy: 0.7234 - recall: 0.7099 - val_loss: 0.5423 - val_accuracy: 0.7300 - val_recall: 0.7108\n",
            "Epoch 72/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5484 - accuracy: 0.7229 - recall: 0.7093 - val_loss: 0.5460 - val_accuracy: 0.7232 - val_recall: 0.7914\n",
            "Epoch 73/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5480 - accuracy: 0.7221 - recall: 0.7100 - val_loss: 0.5431 - val_accuracy: 0.7302 - val_recall: 0.7748\n",
            "Epoch 74/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.5480 - accuracy: 0.7239 - recall: 0.7108 - val_loss: 0.5482 - val_accuracy: 0.7284 - val_recall: 0.6507\n",
            "Epoch 75/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5470 - accuracy: 0.7224 - recall: 0.7100 - val_loss: 0.5465 - val_accuracy: 0.7282 - val_recall: 0.6618\n",
            "Epoch 76/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5460 - accuracy: 0.7247 - recall: 0.7107 - val_loss: 0.5429 - val_accuracy: 0.7306 - val_recall: 0.7195\n",
            "Epoch 77/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5464 - accuracy: 0.7260 - recall: 0.7141 - val_loss: 0.5407 - val_accuracy: 0.7310 - val_recall: 0.7033\n",
            "Epoch 78/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.5456 - accuracy: 0.7237 - recall: 0.7106 - val_loss: 0.5427 - val_accuracy: 0.7320 - val_recall: 0.7499\n",
            "Epoch 79/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5463 - accuracy: 0.7235 - recall: 0.7082 - val_loss: 0.5415 - val_accuracy: 0.7282 - val_recall: 0.7614\n",
            "Epoch 80/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5461 - accuracy: 0.7253 - recall: 0.7127 - val_loss: 0.5447 - val_accuracy: 0.7270 - val_recall: 0.6689\n",
            "Epoch 81/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5460 - accuracy: 0.7258 - recall: 0.7127 - val_loss: 0.5402 - val_accuracy: 0.7298 - val_recall: 0.7527\n",
            "Epoch 82/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5452 - accuracy: 0.7241 - recall: 0.7104 - val_loss: 0.5407 - val_accuracy: 0.7294 - val_recall: 0.7531\n",
            "Epoch 83/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5461 - accuracy: 0.7259 - recall: 0.7124 - val_loss: 0.5412 - val_accuracy: 0.7298 - val_recall: 0.6985\n",
            "Epoch 84/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5445 - accuracy: 0.7248 - recall: 0.7082 - val_loss: 0.5428 - val_accuracy: 0.7304 - val_recall: 0.7732\n",
            "Epoch 85/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5447 - accuracy: 0.7258 - recall: 0.7121 - val_loss: 0.5401 - val_accuracy: 0.7300 - val_recall: 0.6985\n",
            "Epoch 86/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5439 - accuracy: 0.7261 - recall: 0.7115 - val_loss: 0.5401 - val_accuracy: 0.7308 - val_recall: 0.7171\n",
            "Epoch 87/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5441 - accuracy: 0.7264 - recall: 0.7139 - val_loss: 0.5419 - val_accuracy: 0.7304 - val_recall: 0.7056\n",
            "Epoch 88/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.5445 - accuracy: 0.7276 - recall: 0.7143 - val_loss: 0.5395 - val_accuracy: 0.7316 - val_recall: 0.7286\n",
            "Epoch 89/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5446 - accuracy: 0.7247 - recall: 0.7107 - val_loss: 0.5399 - val_accuracy: 0.7304 - val_recall: 0.7361\n",
            "Epoch 90/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5448 - accuracy: 0.7264 - recall: 0.7138 - val_loss: 0.5447 - val_accuracy: 0.7304 - val_recall: 0.6634\n",
            "Epoch 91/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.5439 - accuracy: 0.7257 - recall: 0.7102 - val_loss: 0.5421 - val_accuracy: 0.7274 - val_recall: 0.7645\n",
            "Epoch 92/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5438 - accuracy: 0.7264 - recall: 0.7136 - val_loss: 0.5519 - val_accuracy: 0.7250 - val_recall: 0.6175\n",
            "Epoch 93/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5436 - accuracy: 0.7254 - recall: 0.7105 - val_loss: 0.5426 - val_accuracy: 0.7276 - val_recall: 0.7740\n",
            "Epoch 94/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5425 - accuracy: 0.7287 - recall: 0.7169 - val_loss: 0.5393 - val_accuracy: 0.7338 - val_recall: 0.7487\n",
            "Epoch 95/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.5435 - accuracy: 0.7268 - recall: 0.7123 - val_loss: 0.5414 - val_accuracy: 0.7276 - val_recall: 0.7598\n",
            "Epoch 96/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5437 - accuracy: 0.7279 - recall: 0.7147 - val_loss: 0.5414 - val_accuracy: 0.7262 - val_recall: 0.6835\n",
            "Epoch 97/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5440 - accuracy: 0.7261 - recall: 0.7126 - val_loss: 0.5388 - val_accuracy: 0.7314 - val_recall: 0.7143\n",
            "Epoch 98/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.5434 - accuracy: 0.7263 - recall: 0.7148 - val_loss: 0.5416 - val_accuracy: 0.7308 - val_recall: 0.6942\n",
            "Epoch 99/100\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5438 - accuracy: 0.7272 - recall: 0.7132 - val_loss: 0.5412 - val_accuracy: 0.7266 - val_recall: 0.6792\n",
            "Epoch 100/100\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.5422 - accuracy: 0.7298 - recall: 0.7143 - val_loss: 0.5387 - val_accuracy: 0.7302 - val_recall: 0.7369\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRfY0ExkPn0Y",
        "outputId": "9b556d7e-5fba-4e5a-a227-9d3770af80f5"
      },
      "source": [
        "history.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'recall', 'val_loss', 'val_accuracy', 'val_recall'])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "qpnPDcCxM7gJ",
        "outputId": "45b241ef-7bbf-4aea-bfe0-01cd80059530"
      },
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history['accuracy'])\n",
        "plt.plot(history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "vS4YkhDIQZrd",
        "outputId": "163c7fd0-8bf5-4543-f31d-1c9564453098"
      },
      "source": [
        "# summarize history for loss\n",
        "plt.plot(history['loss'])\n",
        "plt.plot(history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LMDFUqGQol5",
        "outputId": "8fb401dd-40ef-4aff-a7e9-e7c776832f1e"
      },
      "source": [
        "# prediction for unseen data\n",
        "pred_Y = Classifier.predict(test_data_reshaped, verbose = True)\n",
        "pred_Y = np.round(pred_Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 1s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "py_1o5Xji20Y",
        "outputId": "0865a4f9-ff12-49f8-ca1d-a0e7ceabbdb1"
      },
      "source": [
        "#get the accuracy_score for prediction # classifer\n",
        "print('Accuracy for test dataset:',accuracy_score(y_test_labels.numpy(), pred_Y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for test dataset: 0.71968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A70lwxlIHvRT",
        "outputId": "c2339750-57e6-49c2-edd4-359470ad8780"
      },
      "source": [
        "# confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test_labels.numpy(), pred_Y)\n",
        "print(conf_matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[9043 3457]\n",
            " [3551 8949]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5n7B4j5e8RM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a13e0d0-ffc3-4c8f-9b7d-be8ef0d5f50d"
      },
      "source": [
        "# classification report\n",
        "print(classification_report(y_test_labels.numpy(), pred_Y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.72      0.72     12500\n",
            "           1       0.72      0.72      0.72     12500\n",
            "\n",
            "    accuracy                           0.72     25000\n",
            "   macro avg       0.72      0.72      0.72     25000\n",
            "weighted avg       0.72      0.72      0.72     25000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmoVy54lM8vz"
      },
      "source": [
        "### Logistic Regression\n",
        "Now lets try with simple logistic regression. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2robghPEhtS"
      },
      "source": [
        "# Instantiate the logistic regression\n",
        "logreg = LogisticRegression()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FW8Fk51rFloQ"
      },
      "source": [
        "# Train the logistic model by fitting the train data\n",
        "logreg = logreg.fit(Xembd_layer, train_labels_batch.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES0meResFytV"
      },
      "source": [
        "# Now lets predict the validation dataset with trainded logistic model\n",
        "prd = logreg.predict(test_emb_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FM56mv6KGNN2",
        "outputId": "291ae3df-4834-47ad-e967-bd1f6ceef253"
      },
      "source": [
        "# Check for the accuracy score for model prediction\n",
        "print('Accuracy for test dataset:',accuracy_score(y_test_labels.numpy(), prd))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for test dataset: 0.7406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmplemDpLbEi",
        "outputId": "d6a0e035-6a06-4637-88a8-1275a04f0889"
      },
      "source": [
        "# confusion matrix\n",
        "confusion = confusion_matrix(y_test_labels.numpy(), prd)\n",
        "print(confusion)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[9476 3024]\n",
            " [3461 9039]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTMCrckwOmsc",
        "outputId": "d2a22fc4-e42b-4ee9-ddbc-015ca5c4b41d"
      },
      "source": [
        "# classification\n",
        "print(classification_report(y_test_labels.numpy(), prd))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.76      0.75     12500\n",
            "           1       0.75      0.72      0.74     12500\n",
            "\n",
            "    accuracy                           0.74     25000\n",
            "   macro avg       0.74      0.74      0.74     25000\n",
            "weighted avg       0.74      0.74      0.74     25000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LESdP8Va0Tc"
      },
      "source": [
        "## Conclusion\n",
        "* Here we created **Sentiment Analysis** models(Sparse_CNN_Autoencoder and Logistic_regression) by training it with IMBD dataset. Where a trained model can predict 1(Positive) or 0(Negative) for given user review.\n",
        "\n",
        "* By comparing the results of Sparse Autoencoder of CNN model and Logistic regression models, Logistic regression performed well but it doesn't mean best model because CNN(Sparse Autoencoder) model only extracting important by learning redundant features in the dataset by preventing model overfitting.\n",
        "\n",
        "* We can improve CNN model by modifying the CNN architecture, where it can learn latent features which are more affected the target variable.\n",
        "\n"
      ]
    }
  ]
}